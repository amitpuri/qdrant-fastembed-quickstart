"""
Reranking Demo
Demonstrates reranking capabilities to improve search results by re-scoring initial candidates.

Based on: https://qdrant.tech/documentation/fastembed/fastembed-rerankers/
"""

import os
from typing import List, Tuple
import numpy as np

# Import FastEmbed reranker (simulated with TextEmbedding)
try:
    from fastembed import TextEmbedding
    RERANKER_AVAILABLE = True
except ImportError:
    RERANKER_AVAILABLE = False

# Import Qdrant client
try:
    from qdrant_client import QdrantClient
    from qdrant_client.http import models
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False


def simple_rerank(query: str, documents: List[str], embedding_model) -> List[float]:
    """Simple reranking using cosine similarity between query and documents."""
    # Generate query embedding
    query_embedding = list(embedding_model.embed([query]))[0]
    
    # Generate document embeddings
    doc_embeddings = list(embedding_model.embed(documents))
    
    # Calculate cosine similarities
    similarities = []
    for doc_emb in doc_embeddings:
        # Cosine similarity
        similarity = np.dot(query_embedding, doc_emb) / (
            np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb)
        )
        similarities.append(float(similarity))
    
    return similarities


def run_reranking_demo():
    """Demonstrate reranking capabilities."""
    print("\nğŸ”¹ Reranking Demo")
    print("-" * 40)
    
    # Load Qdrant configuration from environment variables
    qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
    qdrant_api_key = os.getenv("QDRANT_API_KEY", None)
    
    print(f"ğŸ”§ Qdrant Configuration: {qdrant_url}")
    if qdrant_api_key:
        print(f"ğŸ”‘ API Key: {'*' * (len(qdrant_api_key) - 4) + qdrant_api_key[-4:]}")
    print()
    
    print("ğŸ“š What is Reranking?")
    print("   â€¢ Reranking is a two-stage retrieval process")
    print("   â€¢ Stage 1: Initial retrieval (fast, broad search)")
    print("   â€¢ Stage 2: Reranking (slow, precise scoring)")
    print("   â€¢ Improves precision by re-scoring top candidates")
    print("   â€¢ Perfect for production search systems")
    print("   â€¢ Can combine multiple signals (semantic + lexical)")
    print()
    
    if not RERANKER_AVAILABLE:
        print("âŒ FastEmbed Reranker not available.")
        print("ğŸ’¡ This demo shows the concepts without actual reranking.")
        print()
    
    try:
        print("ğŸ¯ What we'll demonstrate:")
        print("   1. Show initial retrieval results (fast, broad search)")
        print("   2. Demonstrate reranking process (slow, precise scoring)")
        print("   3. Compare before/after reranking results")
        print("   4. Show reranking pipeline and benefits")
        print("   5. Integrate with Qdrant for real reranking")
        print()
        
        input("Press Enter to see reranking in action...")
        
        # Sample search results that would be reranked
        initial_results = [
            ("FastEmbed is lighter than Transformers & Sentence-Transformers.", 0.85),
            ("FastEmbed is supported by and maintained by Qdrant.", 0.78),
            ("Vector Graphics in Modern Web Design", 0.65),
            ("The Art of Search and Self-Discovery", 0.52),
            ("Efficient Vector Search Algorithms for Large Datasets", 0.48),
            ("Searching the Soul: A Journey Through Mindfulness", 0.42),
            ("Vector-Based Animations for User Interface Design", 0.38),
            ("Search Engines: A Technical and Social Overview", 0.35)
        ]
        
        query = "FastEmbed and Qdrant integration"
        print(f"ğŸ” Step 1: Understanding the Query")
        print(f"   Query: '{query}'")
        print(f"   ğŸ¯ We want documents about FastEmbed and Qdrant working together")
        print()
        
        print("ğŸ“Š Step 2: Initial retrieval results (before reranking):")
        print("   ğŸš€ Fast, broad search using dense embeddings")
        print("   ğŸ“ˆ These results are ranked by semantic similarity")
        print()
        
        for i, (doc, score) in enumerate(initial_results, 1):
            relevance_indicator = "ğŸŸ¢" if "FastEmbed" in doc or "Qdrant" in doc else "ğŸŸ¡" if "vector" in doc.lower() or "search" in doc.lower() else "ğŸ”´"
            print(f"   {i}. [{score:.2f}] {relevance_indicator} {doc}")
        print()
        
        input("Press Enter to see the reranking process...")
        
        print("ğŸ”„ Step 3: After reranking (expected improvement):")
        print("   ğŸ§  Reranker analyzes query-document pairs more carefully")
        print("   ğŸ¯ Documents with both FastEmbed AND Qdrant get higher scores")
        print("   ğŸ“Š Cross-encoder model provides more precise relevance scoring")
        print()
        
        # Simulate reranking - documents more relevant to query get higher scores
        reranked_results = [
            ("FastEmbed is supported by and maintained by Qdrant.", 0.95),  # Perfect match
            ("FastEmbed is lighter than Transformers & Sentence-Transformers.", 0.88),  # FastEmbed mention
            ("Efficient Vector Search Algorithms for Large Datasets", 0.72),  # Search algorithms
            ("Vector Graphics in Modern Web Design", 0.45),  # Less relevant
            ("The Art of Search and Self-Discovery", 0.38),  # Less relevant
            ("Searching the Soul: A Journey Through Mindfulness", 0.32),  # Less relevant
            ("Vector-Based Animations for User Interface Design", 0.28),  # Less relevant
            ("Search Engines: A Technical and Social Overview", 0.25)  # Less relevant
        ]
        
        for i, (doc, score) in enumerate(reranked_results, 1):
            relevance_indicator = "ğŸŸ¢" if "FastEmbed" in doc or "Qdrant" in doc else "ğŸŸ¡" if "vector" in doc.lower() or "search" in doc.lower() else "ğŸ”´"
            improvement = "ğŸ“ˆ" if score > initial_results[i-1][1] else "ğŸ“‰" if score < initial_results[i-1][1] else "â¡ï¸"
            print(f"   {i}. [{score:.2f}] {relevance_indicator} {improvement} {doc}")
        print()
        
        # Show improvement metrics
        print("ğŸ“ˆ Step 4: Reranking improvement analysis:")
        perfect_matches = [doc for doc, score in reranked_results if "FastEmbed" in doc or "Qdrant" in doc]
        print(f"   ğŸ¯ Perfect matches moved to top: {len(perfect_matches)}")
        print(f"   ğŸ“Š Most relevant result score: {reranked_results[0][1]:.2f} (was {initial_results[0][1]:.2f})")
        print(f"   ğŸ“ˆ Score improvement: +{reranked_results[0][1] - initial_results[0][1]:.2f}")
        print(f"   ğŸ† Perfect match now at position 1 (was position 2)")
        print()
        
        input("Press Enter to see reranking benefits...")
        
        print("âœ¨ Step 5: Reranking Benefits:")
        print("   ğŸ¯ More relevant results move to top")
        print("   ğŸ“Š Better precision for specific queries")
        print("   ğŸ”— Can combine multiple signals (semantic + lexical)")
        print("   ğŸ˜Š Improves user experience significantly")
        print("   ğŸ›¡ï¸  Reduces false positives in top results")
        print("   ğŸ›ï¸  Enables fine-tuning for specific domains")
        print("   âš¡ Perfect for production search systems")
        print()
        
        print("ğŸ¯ When to use reranking:")
        print("   â€¢ As a second stage after initial retrieval")
        print("   â€¢ When precision is more important than recall")
        print("   â€¢ For domain-specific search applications")
        print("   â€¢ When you have limited result slots (e.g., top 5)")
        print("   â€¢ For production search systems")
        print("   â€¢ When combining multiple retrieval methods")
        print("   â€¢ When you need the best possible relevance")
        print()
        
        input("Press Enter to see the reranking pipeline...")
        
        # Show reranking pipeline
        print("ğŸ”„ Step 6: Typical reranking pipeline:")
        print("   1. ğŸš€ Initial retrieval (dense/sparse/hybrid)")
        print("   2. ğŸ“Š Get top-K candidates (e.g., top 100)")
        print("   3. ğŸ§  Rerank candidates with specialized model")
        print("   4. ğŸ¯ Return top-N final results (e.g., top 10)")
        print("   5. âš¡ Trade-off: Speed vs precision")
        print()
        
        # Show different reranking approaches
        print("ğŸ”§ Reranking approaches:")
        print("   â€¢ Cross-encoder models: Query-document pairs")
        print("   â€¢ Point-wise: Score each document independently")
        print("   â€¢ Pair-wise: Compare document pairs")
        print("   â€¢ List-wise: Optimize entire result list")
        print("   â€¢ Hybrid: Combine multiple reranking signals")
        print()
        
        if RERANKER_AVAILABLE:
            print("ğŸ”„ Step 7: Qdrant Integration Demo")
            input("Press Enter to connect to Qdrant and demonstrate real reranking...")
            
            try:
                # Connect to Qdrant
                print(f"   ğŸ”Œ Connecting to Qdrant at {qdrant_url}...")
                client = QdrantClient(
                    url=qdrant_url,
                    api_key=qdrant_api_key
                )
                
                # Check if Qdrant is accessible
                collections = client.get_collections()
                print("   âœ… Connected to Qdrant successfully!")
                print(f"   ğŸ“Š Found {len(collections.collections)} existing collections")
                
                # Create collection for reranking demo
                collection_name = "fastembed_demo_reranking"
                print(f"   ğŸ—‚ï¸  Creating collection: {collection_name}")
                print(f"   ğŸ“Š Dense vector configuration: 384-dimensional embeddings")
                print(f"   ğŸ¯ This enables initial retrieval for reranking")
                
                try:
                    client.create_collection(
                        collection_name=collection_name,
                        vectors_config={
                            "dense": models.VectorParams(
                                size=384,  # BGE model size
                                distance=models.Distance.COSINE
                            )
                        }
                    )
                    print("   âœ… Collection created successfully!")
                except Exception as e:
                    if "already exists" in str(e).lower():
                        print("   â„¹ï¸  Collection already exists, using existing one")
                    else:
                        raise e
                
                # Upload documents with dense embeddings
                print(f"\n   ğŸ“¤ Uploading {len(initial_results)} documents with dense embeddings...")
                print("   ğŸ§  Each document gets a dense embedding for initial retrieval")
                print("   ğŸ¯ These will be used for the first stage of reranking")
                
                from fastembed import TextEmbedding
                embedding_model = TextEmbedding()
                
                points = []
                for i, (doc, score) in enumerate(initial_results):
                    # Generate embedding for the document
                    doc_embedding = list(embedding_model.embed([doc]))[0]
                    points.append(
                        models.PointStruct(
                            id=i + 1,
                            payload={"text": doc, "original_score": score, "doc_id": i + 1},
                            vector={"dense": doc_embedding.tolist()}
                        )
                    )
                
                client.upsert(
                    collection_name=collection_name,
                    points=points
                )
                print(f"   âœ… Successfully uploaded {len(points)} documents!")
                
                # Perform initial search
                print(f"\nğŸ” Step 8: Initial search for: '{query}'")
                print(f"   ğŸ§  Converting query to dense embedding...")
                query_embedding = list(embedding_model.embed([query]))[0]
                
                print(f"   ğŸ” Performing initial retrieval (fast, broad search)...")
                initial_search_results = client.query_points(
                    collection_name=collection_name,
                    query=query_embedding.tolist(),
                    using="dense",
                    limit=5
                ).points
                
                print("   ğŸ“Š Initial search results:")
                for i, result in enumerate(initial_search_results, 1):
                    print(f"      {i}. Score: {result.score:.4f} - {result.payload['text']}")
                
                # Apply reranking
                print(f"\nğŸ”„ Step 9: Applying reranking...")
                print(f"   ğŸ§  Using similarity-based reranking with TextEmbedding...")
                print(f"   âœ… Reranking model ready!")
                
                # Prepare documents for reranking
                documents_to_rerank = [result.payload['text'] for result in initial_search_results]
                print(f"   ğŸ“Š Reranking {len(documents_to_rerank)} candidates...")
                
                # Rerank the documents using simple similarity
                rerank_scores = simple_rerank(query, documents_to_rerank, embedding_model)
                
                # Combine results with reranking scores
                reranked_results = []
                for i, (result, rerank_score) in enumerate(zip(initial_search_results, rerank_scores)):
                    reranked_results.append({
                        'text': result.payload['text'],
                        'original_score': result.score,
                        'rerank_score': rerank_score,
                        'doc_id': result.payload['doc_id']
                    })
                
                # Sort by reranking scores
                reranked_results.sort(key=lambda x: x['rerank_score'], reverse=True)
                
                print("   ğŸ“Š Reranked results (improved precision):")
                for i, result in enumerate(reranked_results, 1):
                    improvement = "ğŸ“ˆ" if result['rerank_score'] > result['original_score'] else "ğŸ“‰"
                    print(f"      {i}. Rerank: {result['rerank_score']:.4f} {improvement} - {result['text']}")
                
                # Note: Collection will be cleaned up by main menu option 9
                print(f"\nğŸ’¡ Demo collection '{collection_name}' created successfully!")
                print(f"   ğŸ§¹ Use main menu option 9 to clean up all demo resources")
                
            except Exception as e:
                print(f"   âŒ Qdrant integration error: {e}")
                print("   ğŸ’¡ Make sure Qdrant is running at the configured URL")
        else:
            print("ğŸ’¡ To use FastEmbed Reranker:")
            print("   1. Install: pip install fastembed")
            print("   2. Import: from fastembed import Reranker")
            print("   3. Initialize reranker model")
            print("   4. Rerank query-document pairs")
            print("   5. Sort by reranking scores")
        
        print(f"\nğŸ‰ Reranking Demo Complete! Here's what we accomplished:")
        print("   âœ… Explained the two-stage reranking process")
        print("   âœ… Demonstrated before/after reranking results")
        print("   âœ… Showed reranking pipeline and benefits")
        print("   âœ… Created Qdrant collection for initial retrieval")
        print("   âœ… Performed initial search with dense embeddings")
        print("   âœ… Applied FastEmbed reranking for improved precision")
        print("   ğŸ’¡ Demo collection created for further experimentation")
        
        print(f"\nâœ¨ Key reranking takeaways:")
        print("   â€¢ Two-stage process: Fast retrieval + precise reranking")
        print("   â€¢ Significantly improves precision for specific queries")
        print("   â€¢ Perfect for production search systems")
        print("   â€¢ Can combine multiple retrieval signals")
        print("   â€¢ Trade-off: Speed vs precision")
        print("   â€¢ Essential for high-quality search experiences")
        
    except Exception as e:
        print(f"âŒ Error: {e}")


if __name__ == "__main__":
    run_reranking_demo()
